# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# Allow all crawlers for indexing, which is good for a portfolio.
User-agent: *
Allow: /

# Disallow specific AI and scraping bots that may not respect rate limits
# or use content for training without permission.
User-agent: GPTBot
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: Anthropic-AI
Disallow: /

User-agent: Omgilibot
Disallow: /

User-agent: Bytespider
Disallow: / 